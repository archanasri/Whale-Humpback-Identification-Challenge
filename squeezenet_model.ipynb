{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import scipy.misc\n",
    "import torchvision\n",
    "from torchvision import utils, transforms, models\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "from torchsummary import summary\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from PIL import Image\n",
    "import csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of classes:  4251\n"
     ]
    }
   ],
   "source": [
    "# Reading data to create id to label mapping\n",
    "data = pd.read_csv(\"/scratch/tmp/WhaleClassData/train.csv\")\n",
    "label_set = set(data['Id'])\n",
    "num_of_classes = len(label_set)\n",
    "print(\"Number of classes: \", len(label_set))\n",
    "\n",
    "label_to_id = {}\n",
    "id_to_label = {}\n",
    "\n",
    "def create_label_id_maps():\n",
    "    _id = 0 \n",
    "    for label in label_set: \n",
    "        label_to_id[label] = _id \n",
    "        id_to_label[_id] = label\n",
    "        _id += 1\n",
    "\n",
    "create_label_id_maps()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset class definition \n",
    "class WhaleDataset(Dataset):\n",
    "    def __init__(self, csv_file, root_dir, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        if \"train\" in csv_file:\n",
    "            self.whales = pd.read_csv(csv_file)\n",
    "            self.test = 0\n",
    "        else:\n",
    "            self.whales = list(os.listdir(self.root_dir))\n",
    "            self.test = 1\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.whales)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if self.test:\n",
    "            img_name = os.path.join(self.root_dir, self.whales[idx])\n",
    "        else:\n",
    "            img_name = os.path.join(self.root_dir, self.whales.iloc[idx, 0])\n",
    "            \n",
    "        image = Image.open(img_name).convert('RGB')\n",
    "        if self.test:\n",
    "            sample = {'image': image, 'image_name': self.whales[idx]}\n",
    "        else:\n",
    "            label = self.whales.iloc[idx, 1]\n",
    "            label = label_to_id[label]\n",
    "            sample = {'image': image, 'image_name': self.whales.iloc[idx, 0], 'label': label}\n",
    "        if self.transform:\n",
    "            sample['image'] = self.transform(sample['image'])\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining transformations to aid in data augmentation\n",
    "resize_shape = (200, 200)\n",
    "# resize_shape = (700, 1050)\n",
    "\n",
    "transforms_1 = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.Resize(resize_shape),\n",
    "    torchvision.transforms.ColorJitter(hue=.05, saturation=.05),\n",
    "    torchvision.transforms.RandomHorizontalFlip(),\n",
    "    torchvision.transforms.RandomVerticalFlip(p=0.5),\n",
    "    torchvision.transforms.RandomRotation(20, resample=Image.BILINEAR),\n",
    "    torchvision.transforms.RandomAffine(30),\n",
    "    torchvision.transforms.ToTensor()\n",
    "])\n",
    "\n",
    "transform_resize = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.Resize(resize_shape),\n",
    "    torchvision.transforms.ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Train and Valid Datset samplers\n",
    "whale_dataset_1 = WhaleDataset(csv_file=\"/scratch/tmp/WhaleClassData/train.csv\", \n",
    "                             root_dir=\"/scratch/tmp/WhaleClassData/train\",\n",
    "                             transform=transform_resize)\n",
    "whale_dataset_2 = WhaleDataset(csv_file=\"/scratch/tmp/WhaleClassData/train.csv\", \n",
    "                             root_dir=\"/scratch/tmp/WhaleClassData/train\",\n",
    "                             transform=transforms_1)\n",
    "whale_dataset_test = WhaleDataset(csv_file=\"/scratch/tmp/WhaleClassData/test\", \n",
    "                             root_dir=\"/scratch/tmp/WhaleClassData/test/\",\n",
    "                             transform=transform_resize)\n",
    "\n",
    "concat_dataset = torch.utils.data.ConcatDataset([whale_dataset_1, whale_dataset_2])\n",
    "\n",
    "validation_split = .2\n",
    "shuffle_dataset = True\n",
    "random_seed = 42\n",
    "\n",
    "dataset_size = len(concat_dataset)\n",
    "indices = list(range(dataset_size))\n",
    "split = int(np.floor(validation_split * dataset_size))\n",
    "if shuffle_dataset:\n",
    "    np.random.seed(random_seed)\n",
    "    np.random.shuffle(indices)\n",
    "train_indices, val_indices = indices[split:], indices[:split]\n",
    "\n",
    "train_sampler = SubsetRandomSampler(train_indices)\n",
    "valid_sampler = SubsetRandomSampler(val_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking what kind of system you are using\n",
    "try:\n",
    "  import google.colab\n",
    "  from google.colab import drive\n",
    "  from google.colab import files\n",
    "  IN_COLAB = True\n",
    "except:\n",
    "  IN_COLAB = False\n",
    "try:\n",
    "    hostname = !hostname\n",
    "    if 'lab' in hostname[0] and '.sci.utah.edu' in hostname[0]:\n",
    "        IN_CADE = True\n",
    "    else:\n",
    "        IN_CADE = False\n",
    "except:\n",
    "    IN_CADE = False\n",
    "\n",
    "assert(not IN_CADE or not IN_COLAB)\n",
    "\n",
    "#defining the folders where datasets will be, depending on the system\n",
    "machine_being_used = 'cade' if IN_CADE else ('colab' if IN_COLAB else 'other')\n",
    "pre_folder = '/scratch/tmp/' if machine_being_used == 'cade' else './'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_gpu_to_use(minimum_memory_mb = 3800):\n",
    "    gpu_to_use = None\n",
    "    try: \n",
    "        os.environ['CUDA_VISIBLE_DEVICES']\n",
    "        print('GPU already assigned before: ' + str(os.environ['CUDA_VISIBLE_DEVICES']))\n",
    "        return\n",
    "    except:\n",
    "        pass\n",
    "    torch.cuda.empty_cache()\n",
    "    for i in range(16):\n",
    "        free_memory = !nvidia-smi --query-gpu=memory.free -i $i --format=csv,nounits,noheader\n",
    "        if free_memory[0] == 'No devices were found':\n",
    "            break\n",
    "        free_memory = int(free_memory[0])\n",
    "        if free_memory>minimum_memory_mb-500:\n",
    "            gpu_to_use = i\n",
    "            break\n",
    "    if gpu_to_use is None:\n",
    "        print('Could not find any GPU available with the required free memory of ' +str(minimum_memory_mb) + 'MB. Please use a different system for this assignment.')\n",
    "    else:\n",
    "        os.environ['CUDA_VISIBLE_DEVICES'] = str(gpu_to_use)\n",
    "        print('Chosen GPU: ' + str(gpu_to_use))\n",
    "        x = torch.rand((256,1024,minimum_memory_mb-500)).cuda()\n",
    "        x = torch.rand((1,1)).cuda()\n",
    "        del x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chosen GPU: 0\n"
     ]
    }
   ],
   "source": [
    "define_gpu_to_use()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 1 - Squeezenet - Dataset\n",
    "batch_size = 128\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(concat_dataset, batch_size=batch_size, sampler=train_sampler)\n",
    "validation_loader = torch.utils.data.DataLoader(concat_dataset, batch_size=1, sampler=valid_sampler)\n",
    "test_loader = torch.utils.data.DataLoader(whale_dataset_test, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def count_params(model):\n",
    "#     return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "# resnet18 = models.resnet18(pretrained=True)\n",
    "# alexnet = models.alexnet(pretrained=True)\n",
    "# squeezenet = models.squeezenet1_0(pretrained=True)\n",
    "# vgg16 = models.vgg16(pretrained=True)\n",
    "# densenet = models.densenet161(pretrained=True)\n",
    "# inception = models.inception_v3(pretrained=True)\n",
    "# googlenet = models.googlenet(pretrained=True)\n",
    "# shufflenet = models.shufflenetv2(pretrained=True)\n",
    "# print(\"resne      ::\", count_params(resnet18))\n",
    "# print(\"alexn      ::\", count_params(alexnet))\n",
    "# print(\"squeezenet ::\", count_params(squeezenet))\n",
    "# print(\"vgg16      ::\", count_params(vgg16))\n",
    "# print(\"densenet   ::\", count_params(densenet))\n",
    "# print(\"inception  ::\", count_params(inception))\n",
    "# print(\"googlenet  ::\", count_params(googlenet))\n",
    "# print(\"shufflenet ::\", count_params(shufflenet))\n",
    "\n",
    "# param_count_list = [(count_params(resnet18), \"resnet18\"), \n",
    "#                    (count_params(alexnet), \"alexnet\"),\n",
    "#                    (count_params(squeezenet), \"squeezenet\"),\n",
    "#                    (count_params(vgg16), \"vgg16\"), \n",
    "#                    (count_params(densenet), \"densenet\"),\n",
    "#                    (count_params(inception), \"inception\"),\n",
    "#                    (count_params(googlenet), \"googlenet\"),\n",
    "#                    (count_params(shufflenet), \"shufflenet\")]\n",
    "\n",
    "# print(sorted(param_count_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SqueezeNet(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 96, kernel_size=(7, 7), stride=(2, 2))\n",
       "    (1): ReLU(inplace)\n",
       "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
       "    (3): Fire(\n",
       "      (squeeze): Conv2d(96, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (squeeze_activation): ReLU(inplace)\n",
       "      (expand1x1): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (expand1x1_activation): ReLU(inplace)\n",
       "      (expand3x3): Conv2d(16, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (expand3x3_activation): ReLU(inplace)\n",
       "    )\n",
       "    (4): Fire(\n",
       "      (squeeze): Conv2d(128, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (squeeze_activation): ReLU(inplace)\n",
       "      (expand1x1): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (expand1x1_activation): ReLU(inplace)\n",
       "      (expand3x3): Conv2d(16, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (expand3x3_activation): ReLU(inplace)\n",
       "    )\n",
       "    (5): Fire(\n",
       "      (squeeze): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (squeeze_activation): ReLU(inplace)\n",
       "      (expand1x1): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (expand1x1_activation): ReLU(inplace)\n",
       "      (expand3x3): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (expand3x3_activation): ReLU(inplace)\n",
       "    )\n",
       "    (6): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
       "    (7): Fire(\n",
       "      (squeeze): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (squeeze_activation): ReLU(inplace)\n",
       "      (expand1x1): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (expand1x1_activation): ReLU(inplace)\n",
       "      (expand3x3): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (expand3x3_activation): ReLU(inplace)\n",
       "    )\n",
       "    (8): Fire(\n",
       "      (squeeze): Conv2d(256, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (squeeze_activation): ReLU(inplace)\n",
       "      (expand1x1): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (expand1x1_activation): ReLU(inplace)\n",
       "      (expand3x3): Conv2d(48, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (expand3x3_activation): ReLU(inplace)\n",
       "    )\n",
       "    (9): Fire(\n",
       "      (squeeze): Conv2d(384, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (squeeze_activation): ReLU(inplace)\n",
       "      (expand1x1): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (expand1x1_activation): ReLU(inplace)\n",
       "      (expand3x3): Conv2d(48, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (expand3x3_activation): ReLU(inplace)\n",
       "    )\n",
       "    (10): Fire(\n",
       "      (squeeze): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (squeeze_activation): ReLU(inplace)\n",
       "      (expand1x1): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (expand1x1_activation): ReLU(inplace)\n",
       "      (expand3x3): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (expand3x3_activation): ReLU(inplace)\n",
       "    )\n",
       "    (11): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
       "    (12): Fire(\n",
       "      (squeeze): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (squeeze_activation): ReLU(inplace)\n",
       "      (expand1x1): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (expand1x1_activation): ReLU(inplace)\n",
       "      (expand3x3): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (expand3x3_activation): ReLU(inplace)\n",
       "    )\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Dropout(p=0.5)\n",
       "    (1): Conv2d(512, 1000, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (2): ReLU(inplace)\n",
       "    (3): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "squeezenet = models.squeezenet1_0(pretrained=True)\n",
    "squeezenet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 96, 97, 97]          14,208\n",
      "              ReLU-2           [-1, 96, 97, 97]               0\n",
      "         MaxPool2d-3           [-1, 96, 48, 48]               0\n",
      "            Conv2d-4           [-1, 16, 48, 48]           1,552\n",
      "              ReLU-5           [-1, 16, 48, 48]               0\n",
      "            Conv2d-6           [-1, 64, 48, 48]           1,088\n",
      "              ReLU-7           [-1, 64, 48, 48]               0\n",
      "            Conv2d-8           [-1, 64, 48, 48]           9,280\n",
      "              ReLU-9           [-1, 64, 48, 48]               0\n",
      "             Fire-10          [-1, 128, 48, 48]               0\n",
      "           Conv2d-11           [-1, 16, 48, 48]           2,064\n",
      "             ReLU-12           [-1, 16, 48, 48]               0\n",
      "           Conv2d-13           [-1, 64, 48, 48]           1,088\n",
      "             ReLU-14           [-1, 64, 48, 48]               0\n",
      "           Conv2d-15           [-1, 64, 48, 48]           9,280\n",
      "             ReLU-16           [-1, 64, 48, 48]               0\n",
      "             Fire-17          [-1, 128, 48, 48]               0\n",
      "           Conv2d-18           [-1, 32, 48, 48]           4,128\n",
      "             ReLU-19           [-1, 32, 48, 48]               0\n",
      "           Conv2d-20          [-1, 128, 48, 48]           4,224\n",
      "             ReLU-21          [-1, 128, 48, 48]               0\n",
      "           Conv2d-22          [-1, 128, 48, 48]          36,992\n",
      "             ReLU-23          [-1, 128, 48, 48]               0\n",
      "             Fire-24          [-1, 256, 48, 48]               0\n",
      "        MaxPool2d-25          [-1, 256, 24, 24]               0\n",
      "           Conv2d-26           [-1, 32, 24, 24]           8,224\n",
      "             ReLU-27           [-1, 32, 24, 24]               0\n",
      "           Conv2d-28          [-1, 128, 24, 24]           4,224\n",
      "             ReLU-29          [-1, 128, 24, 24]               0\n",
      "           Conv2d-30          [-1, 128, 24, 24]          36,992\n",
      "             ReLU-31          [-1, 128, 24, 24]               0\n",
      "             Fire-32          [-1, 256, 24, 24]               0\n",
      "           Conv2d-33           [-1, 48, 24, 24]          12,336\n",
      "             ReLU-34           [-1, 48, 24, 24]               0\n",
      "           Conv2d-35          [-1, 192, 24, 24]           9,408\n",
      "             ReLU-36          [-1, 192, 24, 24]               0\n",
      "           Conv2d-37          [-1, 192, 24, 24]          83,136\n",
      "             ReLU-38          [-1, 192, 24, 24]               0\n",
      "             Fire-39          [-1, 384, 24, 24]               0\n",
      "           Conv2d-40           [-1, 48, 24, 24]          18,480\n",
      "             ReLU-41           [-1, 48, 24, 24]               0\n",
      "           Conv2d-42          [-1, 192, 24, 24]           9,408\n",
      "             ReLU-43          [-1, 192, 24, 24]               0\n",
      "           Conv2d-44          [-1, 192, 24, 24]          83,136\n",
      "             ReLU-45          [-1, 192, 24, 24]               0\n",
      "             Fire-46          [-1, 384, 24, 24]               0\n",
      "           Conv2d-47           [-1, 64, 24, 24]          24,640\n",
      "             ReLU-48           [-1, 64, 24, 24]               0\n",
      "           Conv2d-49          [-1, 256, 24, 24]          16,640\n",
      "             ReLU-50          [-1, 256, 24, 24]               0\n",
      "           Conv2d-51          [-1, 256, 24, 24]         147,712\n",
      "             ReLU-52          [-1, 256, 24, 24]               0\n",
      "             Fire-53          [-1, 512, 24, 24]               0\n",
      "        MaxPool2d-54          [-1, 512, 12, 12]               0\n",
      "           Conv2d-55           [-1, 64, 12, 12]          32,832\n",
      "             ReLU-56           [-1, 64, 12, 12]               0\n",
      "           Conv2d-57          [-1, 256, 12, 12]          16,640\n",
      "             ReLU-58          [-1, 256, 12, 12]               0\n",
      "           Conv2d-59          [-1, 256, 12, 12]         147,712\n",
      "             ReLU-60          [-1, 256, 12, 12]               0\n",
      "             Fire-61          [-1, 512, 12, 12]               0\n",
      "          Dropout-62          [-1, 512, 12, 12]               0\n",
      "           Conv2d-63         [-1, 1000, 12, 12]         513,000\n",
      "             ReLU-64         [-1, 1000, 12, 12]               0\n",
      "AdaptiveAvgPool2d-65           [-1, 1000, 1, 1]               0\n",
      "================================================================\n",
      "Total params: 1,248,424\n",
      "Trainable params: 1,248,424\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.46\n",
      "Forward/backward pass size (MB): 72.94\n",
      "Params size (MB): 4.76\n",
      "Estimated Total Size (MB): 78.16\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "squeezenet = squeezenet.cuda()\n",
    "summary(squeezenet, input_size=(3, 200, 200))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Identity(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Identity, self).__init__()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 96, 97, 97]          14,208\n",
      "              ReLU-2           [-1, 96, 97, 97]               0\n",
      "         MaxPool2d-3           [-1, 96, 48, 48]               0\n",
      "            Conv2d-4           [-1, 16, 48, 48]           1,552\n",
      "              ReLU-5           [-1, 16, 48, 48]               0\n",
      "            Conv2d-6           [-1, 64, 48, 48]           1,088\n",
      "              ReLU-7           [-1, 64, 48, 48]               0\n",
      "            Conv2d-8           [-1, 64, 48, 48]           9,280\n",
      "              ReLU-9           [-1, 64, 48, 48]               0\n",
      "             Fire-10          [-1, 128, 48, 48]               0\n",
      "           Conv2d-11           [-1, 16, 48, 48]           2,064\n",
      "             ReLU-12           [-1, 16, 48, 48]               0\n",
      "           Conv2d-13           [-1, 64, 48, 48]           1,088\n",
      "             ReLU-14           [-1, 64, 48, 48]               0\n",
      "           Conv2d-15           [-1, 64, 48, 48]           9,280\n",
      "             ReLU-16           [-1, 64, 48, 48]               0\n",
      "             Fire-17          [-1, 128, 48, 48]               0\n",
      "           Conv2d-18           [-1, 32, 48, 48]           4,128\n",
      "             ReLU-19           [-1, 32, 48, 48]               0\n",
      "           Conv2d-20          [-1, 128, 48, 48]           4,224\n",
      "             ReLU-21          [-1, 128, 48, 48]               0\n",
      "           Conv2d-22          [-1, 128, 48, 48]          36,992\n",
      "             ReLU-23          [-1, 128, 48, 48]               0\n",
      "             Fire-24          [-1, 256, 48, 48]               0\n",
      "        MaxPool2d-25          [-1, 256, 24, 24]               0\n",
      "           Conv2d-26           [-1, 32, 24, 24]           8,224\n",
      "             ReLU-27           [-1, 32, 24, 24]               0\n",
      "           Conv2d-28          [-1, 128, 24, 24]           4,224\n",
      "             ReLU-29          [-1, 128, 24, 24]               0\n",
      "           Conv2d-30          [-1, 128, 24, 24]          36,992\n",
      "             ReLU-31          [-1, 128, 24, 24]               0\n",
      "             Fire-32          [-1, 256, 24, 24]               0\n",
      "           Conv2d-33           [-1, 48, 24, 24]          12,336\n",
      "             ReLU-34           [-1, 48, 24, 24]               0\n",
      "           Conv2d-35          [-1, 192, 24, 24]           9,408\n",
      "             ReLU-36          [-1, 192, 24, 24]               0\n",
      "           Conv2d-37          [-1, 192, 24, 24]          83,136\n",
      "             ReLU-38          [-1, 192, 24, 24]               0\n",
      "             Fire-39          [-1, 384, 24, 24]               0\n",
      "           Conv2d-40           [-1, 48, 24, 24]          18,480\n",
      "             ReLU-41           [-1, 48, 24, 24]               0\n",
      "           Conv2d-42          [-1, 192, 24, 24]           9,408\n",
      "             ReLU-43          [-1, 192, 24, 24]               0\n",
      "           Conv2d-44          [-1, 192, 24, 24]          83,136\n",
      "             ReLU-45          [-1, 192, 24, 24]               0\n",
      "             Fire-46          [-1, 384, 24, 24]               0\n",
      "           Conv2d-47           [-1, 64, 24, 24]          24,640\n",
      "             ReLU-48           [-1, 64, 24, 24]               0\n",
      "           Conv2d-49          [-1, 256, 24, 24]          16,640\n",
      "             ReLU-50          [-1, 256, 24, 24]               0\n",
      "           Conv2d-51          [-1, 256, 24, 24]         147,712\n",
      "             ReLU-52          [-1, 256, 24, 24]               0\n",
      "             Fire-53          [-1, 512, 24, 24]               0\n",
      "        MaxPool2d-54          [-1, 512, 12, 12]               0\n",
      "           Conv2d-55           [-1, 64, 12, 12]          32,832\n",
      "             ReLU-56           [-1, 64, 12, 12]               0\n",
      "           Conv2d-57          [-1, 256, 12, 12]          16,640\n",
      "             ReLU-58          [-1, 256, 12, 12]               0\n",
      "           Conv2d-59          [-1, 256, 12, 12]         147,712\n",
      "             ReLU-60          [-1, 256, 12, 12]               0\n",
      "             Fire-61          [-1, 512, 12, 12]               0\n",
      "          Dropout-62          [-1, 512, 12, 12]               0\n",
      "           Conv2d-63         [-1, 1000, 12, 12]         513,000\n",
      "             ReLU-64         [-1, 1000, 12, 12]               0\n",
      "AdaptiveAvgPool2d-65           [-1, 1000, 1, 1]               0\n",
      "================================================================\n",
      "Total params: 1,248,424\n",
      "Trainable params: 1,248,424\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.46\n",
      "Forward/backward pass size (MB): 72.94\n",
      "Params size (MB): 4.76\n",
      "Estimated Total Size (MB): 78.16\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model_1 = models.squeezenet1_0(pretrained=True)\n",
    "model_1.fc = torch.nn.Linear(in_features=1000, out_features=num_of_classes, bias=True)\n",
    "# model_1.classifier[1] = nn.Conv2d(512, num_of_classes, kernel_size=(1,1), stride=(1,1))\n",
    "# model_1.classifier[2] = torch.nn.Linear(in_features=1000, out_features=num_of_classes, bias=True)\n",
    "# model_1.classifier[3] = Identity()\n",
    "\n",
    "model_1 = model_1.cuda()\n",
    "# summary(model_1, input_size=(3, 200, 200))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SqueezeNet(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 96, kernel_size=(7, 7), stride=(2, 2))\n",
       "    (1): ReLU(inplace)\n",
       "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
       "    (3): Fire(\n",
       "      (squeeze): Conv2d(96, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (squeeze_activation): ReLU(inplace)\n",
       "      (expand1x1): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (expand1x1_activation): ReLU(inplace)\n",
       "      (expand3x3): Conv2d(16, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (expand3x3_activation): ReLU(inplace)\n",
       "    )\n",
       "    (4): Fire(\n",
       "      (squeeze): Conv2d(128, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (squeeze_activation): ReLU(inplace)\n",
       "      (expand1x1): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (expand1x1_activation): ReLU(inplace)\n",
       "      (expand3x3): Conv2d(16, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (expand3x3_activation): ReLU(inplace)\n",
       "    )\n",
       "    (5): Fire(\n",
       "      (squeeze): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (squeeze_activation): ReLU(inplace)\n",
       "      (expand1x1): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (expand1x1_activation): ReLU(inplace)\n",
       "      (expand3x3): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (expand3x3_activation): ReLU(inplace)\n",
       "    )\n",
       "    (6): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
       "    (7): Fire(\n",
       "      (squeeze): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (squeeze_activation): ReLU(inplace)\n",
       "      (expand1x1): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (expand1x1_activation): ReLU(inplace)\n",
       "      (expand3x3): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (expand3x3_activation): ReLU(inplace)\n",
       "    )\n",
       "    (8): Fire(\n",
       "      (squeeze): Conv2d(256, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (squeeze_activation): ReLU(inplace)\n",
       "      (expand1x1): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (expand1x1_activation): ReLU(inplace)\n",
       "      (expand3x3): Conv2d(48, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (expand3x3_activation): ReLU(inplace)\n",
       "    )\n",
       "    (9): Fire(\n",
       "      (squeeze): Conv2d(384, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (squeeze_activation): ReLU(inplace)\n",
       "      (expand1x1): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (expand1x1_activation): ReLU(inplace)\n",
       "      (expand3x3): Conv2d(48, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (expand3x3_activation): ReLU(inplace)\n",
       "    )\n",
       "    (10): Fire(\n",
       "      (squeeze): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (squeeze_activation): ReLU(inplace)\n",
       "      (expand1x1): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (expand1x1_activation): ReLU(inplace)\n",
       "      (expand3x3): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (expand3x3_activation): ReLU(inplace)\n",
       "    )\n",
       "    (11): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
       "    (12): Fire(\n",
       "      (squeeze): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (squeeze_activation): ReLU(inplace)\n",
       "      (expand1x1): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (expand1x1_activation): ReLU(inplace)\n",
       "      (expand3x3): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (expand3x3_activation): ReLU(inplace)\n",
       "    )\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Dropout(p=0.5)\n",
       "    (1): Conv2d(512, 1000, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (2): ReLU(inplace)\n",
       "    (3): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  )\n",
       "  (fc): Linear(in_features=1000, out_features=4251, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "torch.Size([128, 3, 200, 200])\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Target size (torch.Size([128, 4251])) must be the same as input size (torch.Size([128, 1000]))",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-b3825a7208a6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0my_onehot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_onehot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_onehot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/env_dir/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/env_dir/lib/python3.7/site-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    615\u001b[0m                                                   \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    616\u001b[0m                                                   \u001b[0mpos_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 617\u001b[0;31m                                                   reduction=self.reduction)\n\u001b[0m\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/env_dir/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mbinary_cross_entropy_with_logits\u001b[0;34m(input, target, weight, size_average, reduce, reduction, pos_weight)\u001b[0m\n\u001b[1;32m   2159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2160\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2161\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Target size ({}) must be the same as input size ({})\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2163\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary_cross_entropy_with_logits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction_enum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Target size (torch.Size([128, 4251])) must be the same as input size (torch.Size([128, 1000]))"
     ]
    }
   ],
   "source": [
    "# Model 1 - squeezenet\n",
    "num_epochs = 5\n",
    "\n",
    "model_1 = models.squeezenet1_0(pretrained=True)\n",
    "# model_1.classifier[1] = nn.Conv2d(512, num_of_classes, kernel_size=(1,1), stride=(1,1))\n",
    "model_1.fc = torch.nn.Linear(in_features=1000, out_features=num_of_classes, bias=True)\n",
    "model_1.cuda()\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model_1.parameters(), lr=0.0001)\n",
    "   \n",
    "for epoch in range(num_epochs): \n",
    "    model_1.train() \n",
    "    losses = []\n",
    "    print('Epoch ' + str(epoch)) \n",
    "    for sample in train_loader:\n",
    "        optimizer.zero_grad() \n",
    "        images = sample['image'].cuda()\n",
    "        print(images.shape)\n",
    "        label = sample['label'].cpu().numpy()\n",
    "        label = label.reshape(label.shape[0],1)\n",
    "        # Creating one hot vector\n",
    "        y_onehot = torch.FloatTensor(label.shape[0], num_of_classes)\n",
    "        y_onehot.zero_()\n",
    "        y_onehot.scatter_(1, torch.LongTensor(label), 1)\n",
    "        y_onehot = y_onehot.cuda()\n",
    "        out = model_1(images)\n",
    "        loss = criterion(out, y_onehot)\n",
    "        loss.backward()\n",
    "        optimizer.step() \n",
    "        losses.append(loss.item())\n",
    "    print('loss: ' + str(np.mean(losses)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# writeFile = open('submission.csv', 'w')\n",
    "# writer = csv.writer(writeFile)\n",
    "# writer.writerow([\"Image\", \"Id\"])\n",
    "\n",
    "model_1.eval()\n",
    "counter = 0\n",
    "acc = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for sample in validation_loader:\n",
    "        images = sample['image'].cuda()\n",
    "#         print (sample['image_name'][0])\n",
    "#         print (counter)\n",
    "#         counter += 1\n",
    "        out = model_1(images)\n",
    "        out = nn.functional.softmax(out)\n",
    "        out = out.cpu().detach().numpy()\n",
    "        ind = np.argsort(out)[0][-5:]\n",
    "#         ind_last = np.argsort(out)[0][-5:]\n",
    "#         print(out)\n",
    "#         print(out[0][ind[0]], \" :: \", out[0][ind[1]])\n",
    "#         print(out[0][ind_last[0]], \" :: \", out[0][ind_last[1]])\n",
    "#         print (int(sample['label'][0]))\n",
    "#         print (ind[0])\n",
    "        if int(sample['label'][0]) in ind : \n",
    "            acc += 1\n",
    "#         if int(sample['label'][0]) == ind[0] or int(sample['label'][0]) == ind[1] or int(sample['label'][0]) == ind[2] or int(sample['label'][0]) == ind[3] or int(sample['label'][0]) == ind[4]:\n",
    "#             acc += 1\n",
    "#         writer.writerow([sample['image_name'][0], id_to_label[ind[0]] + \" \" + id_to_label[ind[1]] + \" \" \n",
    "#                          + id_to_label[ind[2]] + \" \" + id_to_label[ind[3]] + \" \" + id_to_label[ind[4]]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(acc, len(validation_loader))\n",
    "print (\"Accuracy: %f\" % (acc/len(validation_loader)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write to the kaggle submission file \n",
    "\n",
    "print(\"# test files :: \", len(test_loader))\n",
    "writeFile = open('submission.csv', 'w')\n",
    "writer = csv.writer(writeFile)\n",
    "writer.writerow([\"Image\", \"Id\"])\n",
    "\n",
    "lines = [[\"Image\", \"Id\"]]\n",
    "\n",
    "model_1.eval()\n",
    "counter = 0\n",
    "acc = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for sample in test_loader:\n",
    "        images = sample['image'].cuda()\n",
    "#         print (sample['image_name'][0])\n",
    "#         print (counter)\n",
    "        counter += 1\n",
    "        out = model_1(images)\n",
    "        out = nn.functional.softmax(out)\n",
    "        out = out.cpu().detach().numpy()\n",
    "        ind = np.argsort(out)[0][-5:]\n",
    "#         print(ind)\n",
    "#         print (int(sample['label'][0]))\n",
    "#         print (ind[0])\n",
    "#         if int(sample['label'][0]) == ind[0] or int(sample['label'][0]) == ind[1] or int(sample['label'][0]) == ind[2] or int(sample['label'][0]) == ind[3] or int(sample['label'][0]) == ind[4]:\n",
    "#             acc += 1\n",
    "        row = [sample['image_name'][0], id_to_label[ind[-1]] + \" \" + id_to_label[ind[-2]] + \" \" \n",
    "                         + id_to_label[ind[-3]] + \" \" + id_to_label[ind[-4]] + \" \" + id_to_label[ind[-5]]]\n",
    "        lines.append(row)\n",
    "        writer.writerow([sample['image_name'][0], id_to_label[ind[0]] + \" \" + id_to_label[ind[1]] + \" \" \n",
    "                         + id_to_label[ind[2]] + \" \" + id_to_label[ind[3]] + \" \" + id_to_label[ind[4]]])\n",
    "    \n",
    "print(\"# counter:: \", counter)\n",
    "\n",
    "with open('submission_alexnet.csv', 'w') as writeFile:\n",
    "    writer = csv.writer(writeFile)\n",
    "    writer.writerows(lines)\n",
    "\n",
    "#check how many rows are present in the file.\n",
    "with open(\"submission.csv\") as f:\n",
    "    print(\"#rows in submission file :: \",sum(1 for line in f))\n",
    "    \n",
    "with open(\"submission_alexnet.csv\") as f:\n",
    "    print(\"#rows in submission_alexnet file :: \",sum(1 for line in f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun May  5 18:27:20 2019       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 410.72       Driver Version: 410.72       CUDA Version: 10.0     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  Tesla K40c          Off  | 00000000:83:00.0 Off |                    0 |\r\n",
      "| 23%   40C    P0    63W / 235W |      0MiB / 11441MiB |     99%      Default |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                       GPU Memory |\r\n",
      "|  GPU       PID   Type   Process name                             Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|  No running processes found                                                 |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_dir",
   "language": "python",
   "name": "env_dir"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
