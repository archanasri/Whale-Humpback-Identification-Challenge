{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import scipy.misc\n",
    "import torchvision\n",
    "from torchvision import utils, transforms, models\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from PIL import Image\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of classes:  4251\n"
     ]
    }
   ],
   "source": [
    "# Reading data to create id to label mapping\n",
    "data = pd.read_csv(\"/scratch/tmp/WhaleClassData/train.csv\")\n",
    "label_set = set(data['Id'])\n",
    "num_of_classes = len(label_set)\n",
    "print(\"Number of classes: \", len(label_set))\n",
    "\n",
    "label_to_id = {}\n",
    "id_to_label = {}\n",
    "\n",
    "def create_label_id_maps():\n",
    "    _id = 0 \n",
    "    for label in label_set: \n",
    "        label_to_id[label] = _id \n",
    "        id_to_label[_id] = label\n",
    "        _id += 1\n",
    "\n",
    "create_label_id_maps()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset class definition \n",
    "class WhaleDataset(Dataset):\n",
    "    def __init__(self, csv_file, root_dir, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        if \"train\" in csv_file:\n",
    "            self.whales = pd.read_csv(csv_file)\n",
    "            self.test = 0\n",
    "        else:\n",
    "            self.whales = list(os.listdir(self.root_dir))\n",
    "            self.test = 1\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.whales)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if self.test:\n",
    "            img_name = os.path.join(self.root_dir, self.whales[idx])\n",
    "        else:\n",
    "            img_name = os.path.join(self.root_dir, self.whales.iloc[idx, 0])\n",
    "            \n",
    "        image = Image.open(img_name).convert('RGB')\n",
    "        if self.test:\n",
    "            sample = {'image': image, 'image_name': self.whales[idx]}\n",
    "        else:\n",
    "            label = self.whales.iloc[idx, 1]\n",
    "            label = label_to_id[label]\n",
    "            sample = {'image': image, 'image_name': self.whales.iloc[idx, 0], 'label': label}\n",
    "        if self.transform:\n",
    "            sample['image'] = self.transform(sample['image'])\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining transformations to aid in data augmentation\n",
    "resize_shape = (200, 200)\n",
    "# resize_shape = (700, 1050)\n",
    "\n",
    "transforms_1 = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.Resize(resize_shape),\n",
    "    torchvision.transforms.ColorJitter(hue=.05, saturation=.05),\n",
    "    torchvision.transforms.RandomHorizontalFlip(),\n",
    "    torchvision.transforms.RandomVerticalFlip(p=0.5),\n",
    "    torchvision.transforms.RandomRotation(20, resample=Image.BILINEAR),\n",
    "    torchvision.transforms.RandomAffine(30),\n",
    "    torchvision.transforms.ToTensor()\n",
    "])\n",
    "\n",
    "transform_resize = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.Resize(resize_shape),\n",
    "    torchvision.transforms.ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Train and Valid Datset samplers\n",
    "whale_dataset_1 = WhaleDataset(csv_file=\"/scratch/tmp/WhaleClassData/train.csv\", \n",
    "                             root_dir=\"/scratch/tmp/WhaleClassData/train\",\n",
    "                             transform=transform_resize)\n",
    "whale_dataset_2 = WhaleDataset(csv_file=\"/scratch/tmp/WhaleClassData/train.csv\", \n",
    "                             root_dir=\"/scratch/tmp/WhaleClassData/train\",\n",
    "                             transform=transforms_1)\n",
    "whale_dataset_test = WhaleDataset(csv_file=\"/scratch/tmp/WhaleClassData/test\", \n",
    "                             root_dir=\"/scratch/tmp/WhaleClassData/test/\",\n",
    "                             transform=transform_resize)\n",
    "\n",
    "concat_dataset = torch.utils.data.ConcatDataset([whale_dataset_1, whale_dataset_2])\n",
    "\n",
    "validation_split = .2\n",
    "shuffle_dataset = True\n",
    "random_seed = 42\n",
    "\n",
    "dataset_size = len(concat_dataset)\n",
    "indices = list(range(dataset_size))\n",
    "split = int(np.floor(validation_split * dataset_size))\n",
    "if shuffle_dataset:\n",
    "    np.random.seed(random_seed)\n",
    "    np.random.shuffle(indices)\n",
    "train_indices, val_indices = indices[split:], indices[:split]\n",
    "\n",
    "train_sampler = SubsetRandomSampler(train_indices)\n",
    "valid_sampler = SubsetRandomSampler(val_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking what kind of system you are using\n",
    "try:\n",
    "  import google.colab\n",
    "  from google.colab import drive\n",
    "  from google.colab import files\n",
    "  IN_COLAB = True\n",
    "except:\n",
    "  IN_COLAB = False\n",
    "try:\n",
    "    hostname = !hostname\n",
    "    if 'lab' in hostname[0] and '.eng.utah.edu' in hostname[0]:\n",
    "        IN_CADE = True\n",
    "    else:\n",
    "        IN_CADE = False\n",
    "except:\n",
    "    IN_CADE = False\n",
    "\n",
    "assert(not IN_CADE or not IN_COLAB)\n",
    "\n",
    "#defining the folders where datasets will be, depending on the system\n",
    "machine_being_used = 'cade' if IN_CADE else ('colab' if IN_COLAB else 'other')\n",
    "pre_folder = '/scratch/tmp/' if machine_being_used == 'cade' else './'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_gpu_to_use(minimum_memory_mb = 3800):\n",
    "    gpu_to_use = None\n",
    "    try: \n",
    "        os.environ['CUDA_VISIBLE_DEVICES']\n",
    "        print('GPU already assigned before: ' + str(os.environ['CUDA_VISIBLE_DEVICES']))\n",
    "        return\n",
    "    except:\n",
    "        pass\n",
    "    torch.cuda.empty_cache()\n",
    "    for i in range(16):\n",
    "        free_memory = !nvidia-smi --query-gpu=memory.free -i $i --format=csv,nounits,noheader\n",
    "        if free_memory[0] == 'No devices were found':\n",
    "            break\n",
    "        free_memory = int(free_memory[0])\n",
    "        if free_memory>minimum_memory_mb-500:\n",
    "            gpu_to_use = i\n",
    "            break\n",
    "    if gpu_to_use is None:\n",
    "        print('Could not find any GPU available with the required free memory of ' +str(minimum_memory_mb) + 'MB. Please use a different system for this assignment.')\n",
    "    else:\n",
    "        os.environ['CUDA_VISIBLE_DEVICES'] = str(gpu_to_use)\n",
    "        print('Chosen GPU: ' + str(gpu_to_use))\n",
    "        x = torch.rand((256,1024,minimum_memory_mb-500)).cuda()\n",
    "        x = torch.rand((1,1)).cuda()\n",
    "        del x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chosen GPU: 0\n"
     ]
    }
   ],
   "source": [
    "define_gpu_to_use()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 1 - Resnet18 - Dataset\n",
    "batch_size = 128\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(concat_dataset, batch_size=batch_size, sampler=train_sampler)\n",
    "validation_loader = torch.utils.data.DataLoader(concat_dataset, batch_size=1, sampler=valid_sampler)\n",
    "test_loader = torch.utils.data.DataLoader(whale_dataset_test, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "loss: 0.15845650209174042\n",
      "Epoch 1\n",
      "loss: 0.013211357091823894\n",
      "Epoch 2\n",
      "loss: 0.006716316272955268\n",
      "Epoch 3\n",
      "loss: 0.004608125572333172\n",
      "Epoch 4\n",
      "loss: 0.0036359487060127\n"
     ]
    }
   ],
   "source": [
    "# Model 1 - Resnet18\n",
    "num_epochs = 5\n",
    "\n",
    "model_1 = models.resnet18(pretrained=True)\n",
    "model_1.fc = torch.nn.Linear(in_features=512, out_features=num_of_classes, bias=True)\n",
    "model_1.cuda()\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model_1.parameters(), lr=0.0001)\n",
    "   \n",
    "for epoch in range(num_epochs): \n",
    "    model_1.train() \n",
    "    losses = []\n",
    "    print('Epoch ' + str(epoch)) \n",
    "    for sample in train_loader:\n",
    "        optimizer.zero_grad() \n",
    "        images = sample['image'].cuda()\n",
    "        label = sample['label'].cpu().numpy()\n",
    "        label = label.reshape(label.shape[0],1)\n",
    "        # Creating one hot vector\n",
    "        y_onehot = torch.FloatTensor(label.shape[0], num_of_classes)\n",
    "        y_onehot.zero_()\n",
    "        y_onehot.scatter_(1, torch.LongTensor(label), 1)\n",
    "        y_onehot = y_onehot.cuda()\n",
    "        out = model_1(images)\n",
    "        loss = criterion(out, y_onehot)\n",
    "        loss.backward()\n",
    "        optimizer.step() \n",
    "        losses.append(loss.item())\n",
    "    print('loss: ' + str(np.mean(losses)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/u0931101/Work/DL_ImgAnal/env_dir/lib/python3.6/site-packages/ipykernel_launcher.py:16: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  app.launch_new_instance()\n"
     ]
    }
   ],
   "source": [
    "# writeFile = open('submission.csv', 'w')\n",
    "# writer = csv.writer(writeFile)\n",
    "# writer.writerow([\"Image\", \"Id\"])\n",
    "\n",
    "model_1.eval()\n",
    "counter = 0\n",
    "acc = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for sample in validation_loader:\n",
    "        images = sample['image'].cuda()\n",
    "#         print (sample['image_name'][0])\n",
    "#         print (counter)\n",
    "#         counter += 1\n",
    "        out = model_1(images)\n",
    "        out = nn.functional.softmax(out)\n",
    "        out = out.cpu().detach().numpy()\n",
    "        ind = np.argsort(out)[0][-5:]\n",
    "#         ind_last = np.argsort(out)[0][-5:]\n",
    "#         print(out)\n",
    "#         print(out[0][ind[0]], \" :: \", out[0][ind[1]])\n",
    "#         print(out[0][ind_last[0]], \" :: \", out[0][ind_last[1]])\n",
    "#         print (int(sample['label'][0]))\n",
    "#         print (ind[0])\n",
    "        if int(sample['label'][0]) in ind : \n",
    "            acc += 1\n",
    "#         if int(sample['label'][0]) == ind[0] or int(sample['label'][0]) == ind[1] or int(sample['label'][0]) == ind[2] or int(sample['label'][0]) == ind[3] or int(sample['label'][0]) == ind[4]:\n",
    "#             acc += 1\n",
    "#         writer.writerow([sample['image_name'][0], id_to_label[ind[0]] + \" \" + id_to_label[ind[1]] + \" \" \n",
    "#                          + id_to_label[ind[2]] + \" \" + id_to_label[ind[3]] + \" \" + id_to_label[ind[4]]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "348 3940\n",
      "Accuracy: 8.832487\n"
     ]
    }
   ],
   "source": [
    "print(acc, len(validation_loader))\n",
    "print (\"Accuracy: %f\" % (acc/len(validation_loader)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# test files ::  15610\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/u0931101/Work/DL_ImgAnal/env_dir/lib/python3.6/site-packages/ipykernel_launcher.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# counter::  15610\n",
      "#rows in submission file ::  15611\n",
      "#rows in submission_resnet18 file ::  15611\n"
     ]
    }
   ],
   "source": [
    "# write to the kaggle submission file \n",
    "\n",
    "print(\"# test files :: \", len(test_loader))\n",
    "writeFile = open('submission.csv', 'w')\n",
    "writer = csv.writer(writeFile)\n",
    "writer.writerow([\"Image\", \"Id\"])\n",
    "\n",
    "lines = [[\"Image\", \"Id\"]]\n",
    "\n",
    "model_1.eval()\n",
    "counter = 0\n",
    "acc = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for sample in test_loader:\n",
    "        images = sample['image'].cuda()\n",
    "#         print (sample['image_name'][0])\n",
    "#         print (counter)\n",
    "        counter += 1\n",
    "        out = model_1(images)\n",
    "        out = nn.functional.softmax(out)\n",
    "        out = out.cpu().detach().numpy()\n",
    "        ind = np.argsort(out)[0][-5:]\n",
    "#         print(ind)\n",
    "#         print (int(sample['label'][0]))\n",
    "#         print (ind[0])\n",
    "#         if int(sample['label'][0]) == ind[0] or int(sample['label'][0]) == ind[1] or int(sample['label'][0]) == ind[2] or int(sample['label'][0]) == ind[3] or int(sample['label'][0]) == ind[4]:\n",
    "#             acc += 1\n",
    "        row = [sample['image_name'][0], id_to_label[ind[-1]] + \" \" + id_to_label[ind[-2]] + \" \" \n",
    "                         + id_to_label[ind[-3]] + \" \" + id_to_label[ind[-4]] + \" \" + id_to_label[ind[-5]]]\n",
    "        lines.append(row)\n",
    "        writer.writerow([sample['image_name'][0], id_to_label[ind[0]] + \" \" + id_to_label[ind[1]] + \" \" \n",
    "                         + id_to_label[ind[2]] + \" \" + id_to_label[ind[3]] + \" \" + id_to_label[ind[4]]])\n",
    "    \n",
    "print(\"# counter:: \", counter)\n",
    "\n",
    "with open('submission_resnet18.csv', 'w') as writeFile:\n",
    "    writer = csv.writer(writeFile)\n",
    "    writer.writerows(lines)\n",
    "\n",
    "#check how many rows are present in the file.\n",
    "with open(\"submission.csv\") as f:\n",
    "    print(\"#rows in submission file :: \",sum(1 for line in f))\n",
    "    \n",
    "with open(\"submission_resnet18.csv\") as f:\n",
    "    print(\"#rows in submission_resnet18 file :: \",sum(1 for line in f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VGG(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace)\n",
       "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (4): ReLU(inplace)\n",
       "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (6): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (7): ReLU(inplace)\n",
       "    (8): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (9): ReLU(inplace)\n",
       "    (10): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (11): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (12): ReLU(inplace)\n",
       "    (13): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (14): ReLU(inplace)\n",
       "    (15): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (16): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (17): ReLU(inplace)\n",
       "    (18): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (19): ReLU(inplace)\n",
       "    (20): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
       "    (1): ReLU(inplace)\n",
       "    (2): Dropout(p=0.5)\n",
       "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (4): ReLU(inplace)\n",
       "    (5): Dropout(p=0.5)\n",
       "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
       "  )\n",
       "  (fc): Linear(in_features=1000, out_features=4251, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vgg_mod = models.vgg11(pretrained=True)\n",
    "\n",
    "vgg_mod.fc = torch.nn.Linear(in_features=1000, out_features=num_of_classes, bias=True)\n",
    "\n",
    "vgg_mod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 625.00 MiB (GPU 0; 3.95 GiB total capacity; 2.81 GiB already allocated; 242.44 MiB free; 434.67 MiB cached)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-d9713be156f0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0my_onehot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLongTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0my_onehot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_onehot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_onehot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Work/DL_ImgAnal/env_dir/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Work/DL_ImgAnal/env_dir/lib/python3.6/site-packages/torchvision/models/vgg.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mavgpool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Work/DL_ImgAnal/env_dir/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Work/DL_ImgAnal/env_dir/lib/python3.6/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Work/DL_ImgAnal/env_dir/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Work/DL_ImgAnal/env_dir/lib/python3.6/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    318\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m         return F.conv2d(input, self.weight, self.bias, self.stride,\n\u001b[0;32m--> 320\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    321\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 625.00 MiB (GPU 0; 3.95 GiB total capacity; 2.81 GiB already allocated; 242.44 MiB free; 434.67 MiB cached)"
     ]
    }
   ],
   "source": [
    "# Model 2 - Resnet18\n",
    "num_epochs = 5\n",
    "\n",
    "model_2 = models.vgg11(pretrained=True)\n",
    "model_2.fc = torch.nn.Linear(in_features=1000, out_features=num_of_classes, bias=True)\n",
    "model_2.cuda()\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model_2.parameters(), lr=0.0001)\n",
    "   \n",
    "for epoch in range(num_epochs): \n",
    "    model_2.train() \n",
    "    losses = []\n",
    "    print('Epoch ' + str(epoch)) \n",
    "    for sample in train_loader:\n",
    "        optimizer.zero_grad() \n",
    "        images = sample['image'].cuda()\n",
    "        label = sample['label'].cpu().numpy()\n",
    "        label = label.reshape(label.shape[0],1)\n",
    "        # Creating one hot vector\n",
    "        y_onehot = torch.FloatTensor(label.shape[0], num_of_classes)\n",
    "        y_onehot.zero_()\n",
    "        y_onehot.scatter_(1, torch.LongTensor(label), 1)\n",
    "        y_onehot = y_onehot.cuda()\n",
    "        out = model_2(images)\n",
    "        loss = criterion(out, y_onehot)\n",
    "        loss.backward()\n",
    "        optimizer.step() \n",
    "        losses.append(loss.item())\n",
    "    print('loss: ' + str(np.mean(losses)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "acc = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for sample in validation_loader:\n",
    "        images = sample['image'].cuda()\n",
    "        out = model(images)\n",
    "        out = nn.functional.softmax(out)\n",
    "        out = out.cpu().detach().numpy()\n",
    "        ind = np.argsort(out)[0][:5]\n",
    "        if int(sample['label'][0]) == ind[0] or int(sample['label'][0]) == ind[1] or int(sample['label'][0]) == ind[2] or int(sample['label'][0]) == ind[3] or int(sample['label'][0]) == ind[4]:\n",
    "            acc += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"Accuracy: %f\" % (acc/len(validation_loader)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 3 - Resnet18\n",
    "num_epochs = 5\n",
    "\n",
    "model_2 = models.resnet18(pretrained=True)\n",
    "model_2.fc = torch.nn.Linear(in_features=512, out_features=num_of_classes, bias=True)\n",
    "model_2.cuda()\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model_2.parameters(), lr=0.001)\n",
    "   \n",
    "for epoch in range(num_epochs): \n",
    "    model_2.train() \n",
    "    losses = []\n",
    "    print('Epoch ' + str(epoch)) \n",
    "    for sample in train_loader:\n",
    "        optimizer.zero_grad() \n",
    "        images = sample['image'].cuda()\n",
    "        label = sample['label'].cpu().numpy()\n",
    "        label = label.reshape(label.shape[0],1)\n",
    "        # Creating one hot vector\n",
    "        y_onehot = torch.FloatTensor(label.shape[0], num_of_classes)\n",
    "        y_onehot.zero_()\n",
    "        y_onehot.scatter_(1, torch.LongTensor(label), 1)\n",
    "        y_onehot = y_onehot.cuda()\n",
    "        out = model_2(images)\n",
    "        loss = criterion(out, y_onehot)\n",
    "        loss.backward()\n",
    "        optimizer.step() \n",
    "        losses.append(loss.item())\n",
    "    print('loss: ' + str(np.mean(losses)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2.eval()\n",
    "acc = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for sample in validation_loader:\n",
    "        images = sample['image'].cuda()\n",
    "        out = model_2(images)\n",
    "        out = nn.functional.softmax(out)\n",
    "        out = out.cpu().detach().numpy()\n",
    "        ind = np.argsort(out)[0][:5]\n",
    "        if int(sample['label'][0]) == ind[0] or int(sample['label'][0]) == ind[1] or int(sample['label'][0]) == ind[2] or int(sample['label'][0]) == ind[3] or int(sample['label'][0]) == ind[4]:\n",
    "            acc += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun May  5 14:57:46 2019       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 418.56       Driver Version: 418.56       CUDA Version: 10.1     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  GeForce GTX 970     Off  | 00000000:01:00.0  On |                  N/A |\r\n",
      "| 11%   49C    P8    17W / 163W |   3804MiB /  4039MiB |      0%      Default |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                       GPU Memory |\r\n",
      "|  GPU       PID   Type   Process name                             Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|    0      5564      C   ...101/Work/DL_ImgAnal/env_dir/bin/python3  3767MiB |\r\n",
      "|    0      7782      G   /usr/bin/X                                    32MiB |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_dir",
   "language": "python",
   "name": "env_dir"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
